# Videos Publications Collectioin

Humans are born to see, and to adapt to this visual world. After the visual signal stimulates the neurons, we learn concepts. we associate one thing with another, seeing waterfall we think about the galaxy, we imagine, and we finally create, updating this visual world. And some of us are trying to gift this ability to intelligent agent, leading an unprecedented scientific trend.

This is a collection of video publications I have recently read, including Action Recognition, Video Generation, Video Self-supervised Learning and some classical papers, etc..

This repo will keep updating during my research.



## Classic

[VideoTextures](Classic/VideoTextures.md)




## Video Generation

[DVDGAN](VideoGeneration/DVDGAN.md)

SV2P

SAVP

SVG-LP

Vid2Vid

[Sig2Vid](https://github.com/antony0621/Publications-of-Video/blob/master/VideoGeneration/Seg2Vid.md)

TGAN

Generating Videos with Scene Dynamics

Generating the Futures with Adversarial Transformers

* **Video Disentangle** 

  [MoCoGAN](https://github.com/antony0621/Publications-of-Video/blob/master/VideoGeneration/MoCoGAN.md)

  [TwoStreamVAN](https://github.com/antony0621/Publications-of-Video/blob/master/VideoGeneration/TwoStreamVAN.md)

  RecycleGAN

  Deep Visual Analogy-Making

  Unsupervised Learning of Disentangled Representations from Video

* **Future Prediction**

  Hierarchical Long-term Video Prediction without Supervision

  Compositional Video Prediction

  An Uncertain Future: Forecasting from Static Images using Variational Autoencoders

  Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks

  Memory In Memory: A Predictive Neural Network for Learning Higher-Order Non-Stationarity from Spatiotemporal Dynamics



## Video Self-supervised Learning

Learning and Using the Arrow of Time

Self-supervised Learning for Video Correspondence Flow

Temporal Cycle-Consistency Learning

Tracking Emerges by Colorizing Videos

Video Representation Learning by Dense Predictive Coding

Shuffle and Learn

Odd-One-Out



## Action Recogniition & Representation Learning

Two-Stream Fusion Network

Delving Deeper into Convolutional Networks for Learning Video Representations



## Video Inpainting

Copy-and-Paste

Deep Video Inpainting

Deep Flow-Guided Video Inpaiting

Onion-Peel Network

Free-Form Video Inpaiting with 3D Gated Convolution and Temporal PatchGAN

Learnable Gated Temporal Shift Module for Video Inpaiting

Video Inpaiting by Jointly Learning Temporal Structure and Spatial Details

Deep Blind Video Decaptioning by Temporal Aggregation and Recurrence

Learning Joint Spatial-Temporal Transformations for Video Inpainting



## Spatio-Temporal Reasoning

Temporal Relational Reasoning in Videos

Videos as Space-Time Region Graphs

Structural-RNN: Deep Learning on Spatio-Temporal Graphs

Relational Action Forecasting

Learning Human-Object Interactions by Graph Parsing Neural Networks



## Video Interpolation

Super SloMo

All at Once: Temporally Adaptive Multi-Frame Interpolation with Advanced Motion Modeling



## Temporal Coherence

Slow and Steady Feature Analysis: Higher Order Temporal Coherence in Video

Learning Blind Video Temporal Consistency



## Video Object Segmentation

Zero-Shot Video Object Segmentation via Attentive Graph Neural Networks



## Visual Dialog & Visual Question Answering

Reasoning Visual Dialogs with Structural and Partial Observations



## Key-Point & Skeleton

Convolutional Sequence Generation for Skeleton-Based Action Synthesis

Unsupervised Keypoint Learning for Guiding Class-Conditional Video Prediction



## Others

What Makes a Video a Video







